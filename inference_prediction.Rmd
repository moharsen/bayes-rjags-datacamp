---
title: "Bayesian Inference and Prediction"
author: "Mohar Sen"
date: "6/14/2020"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chapter 3 goals
+ Engineer a simple Bayesian regression model
+ Define, compile, and simulate regression models in RJAGS
+ Use Markov chain simulation output for posterior inference & prediction

```{r}
library(ggplot2)
library(rjags)
library(dplyr)
```
## Regression priors
Let $Y_i$ be the weight (in kg) of subject i. Past studies have shown that weight is linearly related to height $X_i$ (in cm). The average weight $m_i$ among adults of any shared height $X_i$ can be written as $m_i =a+bX_i$. But height isn't a perfect predictor of weight - individuals vary from the trend. To this end, it's reasonable to assume that Yi are Normally distributed around $m_i$ with residual standard deviation s: $Y_i \sim N(m_i, s^2)$

Note the 3 parameters in the model of weight by height: intercept $a$, slope $b$, & standard deviation $s$. In the first step of your Bayesian analysis, you will simulate the following prior models for these parameters: $a \sim N(0,200^2)$, $b \sim N(1,0.5^2)$, and $c \sim Unif(0,20)$.

**Instructions**

+ Sample 10,000 draws from each of the a, b, and s priors. Assign the output to a, b, and s. These are subsequently combined in the samples data frame along with set = 1:10000, an indicator of the draw numbers.
+ Construct separate density plots of each of the a, b, and s samples.

```{r}
# Take 10000 samples from the a, b, & s priors
a <- rnorm(10000,0,200)
b <- rnorm(10000,1,0.5)
s <- runif(10000,0,20)

# Store samples in a data frame
samples <- data.frame(set = 1:10000, a, b, s)

# Construct density plots of the prior samples    
ggplot(samples, aes(x = a)) + 
    geom_density()
ggplot(samples, aes(x = b)) + 
    geom_density()
ggplot(samples, aes(x = s)) + 
    geom_density()
```

These simulations approximate your prior models of each separate model parameter. There's likely a positive association between weight & height ($b > 0$) but more uncertainty about the intercept a. Further, at any given height, the typical deviation of individuals' weights from the trend is equally likely to be anywhere between 0 and 20 kg. 


## Visualizing the regression priors

In the previous exercise, you simulated 10,000 samples for each parameter ($a, b, s$) in the Bayesian regression model of weight Y by height X: $Y_i \sim N(m_i, s^2)$ with mean $m=a+bX$. The set of $a$, $b$, and $s$ values in each row of samples represents a prior plausible regression scenario. To explore the scope of these prior scenarios, you will simulate 50 pairs of height and weight values from each of the first 12 sets of prior parameters $a$, $b$, and $s$.


**Instructions**

+ Create a data frame prior_simulation which includes n = 50 replicates of the first 12 sets of prior parameters in samples (600 rows in total!).
+ For each of the 600 prior_simulation rows:
  + Simulate a height value from a $N(170,10^2)$ model.
  + Simulate a weight value from $N(a+bX,s^2)$
  + where $X$ is height and ($a, b, s$) are the prior parameter set. 
+ You now have 50 simulated height and weight pairs for each of the 12 parameter sets. Use `ggplot()` to construct a scatterplot of these 50 pairs for each set of parameter values. Be sure to put weight on the y-axis!

```{r}
# Replicate the first 12 parameter sets 50 times each
prior_scenarios_rep <- bind_rows(replicate(n = 50, expr = samples[1:12, ], simplify = FALSE)) 

# Simulate 50 height & weight data points for each parameter set
prior_simulation <- prior_scenarios_rep %>% 
    mutate(height = rnorm(n = 600, mean = 170, sd = 10)) %>% 
    mutate(weight = rnorm(n = 600, mean = a+b*height, sd = s))

# Plot the simulated data & regression model for each parameter set
ggplot(prior_simulation, aes(x = height, y = weight)) + 
    geom_point() + 
    geom_smooth(method = "lm", se = FALSE, size = 0.75) + 
    facet_wrap(~ set)
```

These 12 plots demonstrate the range of prior plausible models. These models have different intercepts, slopes, and residual standard deviations. Almost all of the models have positive slopes, demonstrating the prior information that there is likely a positive association between weight & height. Given your vague prior for a, some of these models are even biologically impossible! 

## Weight & height data

The `bdims` data set from the `openintro` package contains physical measurements on a sample of 507 individuals, including their weight in kg (wgt) and height in cm (hgt). You will use these data to build insights into the relationship between weight and height.

```{r}
library(openintro)
data("bdims")
```

**instructions**

+ Construct a scatterplot of `wgt` (y-axis) vs `hgt` (x-axis) using `ggplot()` with a `geom_point()` layer.
+ Construct a scatterplot of wgt vs hgt which includes a `geom_smooth()` of the linear relationship between these 2 variables.

```{r}
# Construct a scatterplot of wgt vs hgt
ggplot(bdims, aes(x = hgt, y = wgt)) + 
    geom_point()

# Add a model smooth
ggplot(bdims, aes(x = hgt, y = wgt)) + 
    geom_point() + 
    geom_smooth(method = "lm", se = FALSE)
```

These data support your prior information about a positive association between weight and height. With insights from the priors and data in place, you're ready to simulate the posterior regression model in RJAGS! 












































